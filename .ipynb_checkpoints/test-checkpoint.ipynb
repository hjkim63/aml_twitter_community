{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Harish/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords  \n",
    "import re\n",
    "nltk.download('stopwords')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list1 = []\n",
    "\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('CapitolRiots since:2021-01-05 until:2021-01-07').get_items()): #declare a username \n",
    "    if i>10: #number of tweets you want to scrape\n",
    "        break\n",
    "    tweets_list1.append([tweet.date, tweet.id, tweet.content, tweet.user.username]) #declare the attributes to be returned\n",
    "    \n",
    "# Creating a dataframe from the tweets list above \n",
    "tweets_df2 = pd.DataFrame(tweets_list1, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])\n",
    "\n",
    "# def hashtag_extract(text):\n",
    "#     l = []\n",
    "#     mark_hash = 0\n",
    "#     # for t in text:\n",
    "#     #     print('t = ',t)\n",
    "#     tag = ''\n",
    "#     for i in range(len(text)):\n",
    "#         print('t[i] = ',text[i])\n",
    "#         if text[i] == '#': \n",
    "#             if tag != '': # if hashtag is right next to a previous hashtag\n",
    "#                 print('Im here_1!')\n",
    "#                 l.append(tag)\n",
    "#                 print('l = ',l)\n",
    "#                 tag = ''\n",
    "#                 mark_hash = 0\n",
    "#             else: #if hashtag not next to a previous hashtag\n",
    "#                 print('Im here_2!')\n",
    "#                 mark_hash = 1\n",
    "#         elif mark_hash == 1 and (text[i]!=' ') and i != (len(text)-1) and text[i] != \"\\n\": #if inside a hashtag and you're not at the end of the text or the end of a line\n",
    "#             tag += text[i]\n",
    "#             print('Im here_3!')\n",
    "#             print('tag = ', tag)\n",
    "#         elif mark_hash == 1 and (text[i] ==' ' or text[i] == \"\\n\"): #if inside a hashtag and you're an empty space or the end of a line\n",
    "#             print('Im here_4!')\n",
    "#             l.append(tag)\n",
    "#             #print('l = ',l)\n",
    "#             tag = ''\n",
    "#             mark_hash = 0\n",
    "#         elif mark_hash == 1 and (i == (len(text) - 1)): #if inside a hashtag and you're not at the end of the text\n",
    "#             tag += text[i]\n",
    "#             l.append(tag)\n",
    "#             tag = ''\n",
    "#             mark_hash = 0\n",
    "#         else:\n",
    "#             tag = ''\n",
    "#     return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-06 23:59:53+00:00</td>\n",
       "      <td>1346969770243940352</td>\n",
       "      <td>Dear generation Y &amp;amp; Z,\\n\\nStop playing #Fo...</td>\n",
       "      <td>ZouhairSaddiki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-06 23:59:31+00:00</td>\n",
       "      <td>1346969679470813184</td>\n",
       "      <td>25th Amendment. Now.\\n#CapitolHill #CapitolRio...</td>\n",
       "      <td>InSituMag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06 23:58:52+00:00</td>\n",
       "      <td>1346969514680922113</td>\n",
       "      <td>Aye @CapitolPolice did you at least pinch the ...</td>\n",
       "      <td>MikeGrands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-06 23:58:46+00:00</td>\n",
       "      <td>1346969487736770563</td>\n",
       "      <td>@tedcruz so @tedcruz will you be resicinding y...</td>\n",
       "      <td>oldwomansage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-06 23:58:42+00:00</td>\n",
       "      <td>1346969473933332485</td>\n",
       "      <td>\"We had better plan now for an involuntary ext...</td>\n",
       "      <td>PamMHarris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-06 23:58:25+00:00</td>\n",
       "      <td>1346969403234127873</td>\n",
       "      <td>If people can enter the #Capitol so easily, so...</td>\n",
       "      <td>Suresh_Gopalan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-01-06 23:58:25+00:00</td>\n",
       "      <td>1346969402286157831</td>\n",
       "      <td>Let’s call it for what it was today: terrorism...</td>\n",
       "      <td>SeanWasson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-01-06 23:58:11+00:00</td>\n",
       "      <td>1346969343242985474</td>\n",
       "      <td>Did the riots today remind anyone else of the ...</td>\n",
       "      <td>kriskline23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-01-06 23:57:47+00:00</td>\n",
       "      <td>1346969242013470720</td>\n",
       "      <td>#whiteprivilege #WhereIsTheLie #Amerika #Remov...</td>\n",
       "      <td>QueenG719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-01-06 23:57:26+00:00</td>\n",
       "      <td>1346969155002515456</td>\n",
       "      <td>#CapitolRiots #RacialJustice #BLM https://t.co...</td>\n",
       "      <td>givingyouthebi1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-01-06 23:57:02+00:00</td>\n",
       "      <td>1346969053357752326</td>\n",
       "      <td>This is the darkest day in U.S. history since ...</td>\n",
       "      <td>iris4wildlife</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Datetime             Tweet Id  \\\n",
       "0  2021-01-06 23:59:53+00:00  1346969770243940352   \n",
       "1  2021-01-06 23:59:31+00:00  1346969679470813184   \n",
       "2  2021-01-06 23:58:52+00:00  1346969514680922113   \n",
       "3  2021-01-06 23:58:46+00:00  1346969487736770563   \n",
       "4  2021-01-06 23:58:42+00:00  1346969473933332485   \n",
       "5  2021-01-06 23:58:25+00:00  1346969403234127873   \n",
       "6  2021-01-06 23:58:25+00:00  1346969402286157831   \n",
       "7  2021-01-06 23:58:11+00:00  1346969343242985474   \n",
       "8  2021-01-06 23:57:47+00:00  1346969242013470720   \n",
       "9  2021-01-06 23:57:26+00:00  1346969155002515456   \n",
       "10 2021-01-06 23:57:02+00:00  1346969053357752326   \n",
       "\n",
       "                                                 Text         Username  \n",
       "0   Dear generation Y &amp; Z,\\n\\nStop playing #Fo...   ZouhairSaddiki  \n",
       "1   25th Amendment. Now.\\n#CapitolHill #CapitolRio...        InSituMag  \n",
       "2   Aye @CapitolPolice did you at least pinch the ...       MikeGrands  \n",
       "3   @tedcruz so @tedcruz will you be resicinding y...     oldwomansage  \n",
       "4   \"We had better plan now for an involuntary ext...       PamMHarris  \n",
       "5   If people can enter the #Capitol so easily, so...   Suresh_Gopalan  \n",
       "6   Let’s call it for what it was today: terrorism...       SeanWasson  \n",
       "7   Did the riots today remind anyone else of the ...      kriskline23  \n",
       "8   #whiteprivilege #WhereIsTheLie #Amerika #Remov...        QueenG719  \n",
       "9   #CapitolRiots #RacialJustice #BLM https://t.co...  givingyouthebi1  \n",
       "10  This is the darkest day in U.S. history since ...    iris4wildlife  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, remove_stopwords = True):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "    text = re.sub(\"#[A-Za-z0-9_]+\",\"\", text)\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "    text =  nltk.WordPunctTokenizer().tokenize(text)\n",
    "    return text\n",
    "\n",
    "def lemmatized_words(text):\n",
    "    lemm = nltk.stem.WordNetLemmatizer()\n",
    "    res = list(map(lambda word:\n",
    "                                     list(map(lemm.lemmatize, word)),\n",
    "                                     text))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/scraped_tweets_#removetrumpnow_10000\n",
      "./data/scraped_tweets_#impeachtrumpnow_10000\n",
      "./data/scraped_tweets_#antifa_10000\n",
      "./data/scraped_tweets_#25thamendmentnow_10000\n",
      "./data/scraped_tweets_#washingtondc_10000\n",
      "./data/scraped_tweets_#merged\n",
      "./data/scraped_tweets_#trumpcouattempt_10000\n",
      "./data/scraped_tweets_#maga_10000\n",
      "./data/scraped_tweets_#capitolriots_10000\n",
      "./data/scraped_tweets_#trump_10000\n",
      "./data/scraped_tweets_#trumptreason_10000\n",
      "[<5001x299 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 21861 stored elements in Compressed Sparse Row format>, <5001x259 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 19598 stored elements in Compressed Sparse Row format>, <5001x485 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 34993 stored elements in Compressed Sparse Row format>, <5001x263 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 18054 stored elements in Compressed Sparse Row format>, <5001x395 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 25056 stored elements in Compressed Sparse Row format>, <40993x2375 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 305887 stored elements in Compressed Sparse Row format>, <5001x578 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 39068 stored elements in Compressed Sparse Row format>, <985x64 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3349 stored elements in Compressed Sparse Row format>, <5001x452 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 31343 stored elements in Compressed Sparse Row format>, <5001x398 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 27826 stored elements in Compressed Sparse Row format>]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bow_arr = []\n",
    "tags_arr = []\n",
    "bow_converter = CountVectorizer(tokenizer=lambda doc: doc, binary = True, min_df = 20, lowercase=False)\n",
    "import os\n",
    "my_dir = './data'\n",
    "for item in os.listdir(my_dir):\n",
    "    if os.path.isfile(os.path.join(my_dir, item)):\n",
    "        print(os.path.join(my_dir, item))\n",
    "        df = pd.read_csv(os.path.join(my_dir, item))\n",
    "        df['Hashtags'] = df['Text'].apply(lambda x: re.findall(r\"#(\\w+)\", x))\n",
    "        lemma_tag = lemmatized_words(df['Hashtags'])\n",
    "        df['text_cleaned'] = list(map(clean_text, df.Text))\n",
    "        lemmatized_words(df.text_cleaned)\n",
    "        #print(df['text_cleaned'])\n",
    "        if len(df['text_cleaned']) != 0:\n",
    "            bow = bow_converter.fit_transform(df['text_cleaned'])\n",
    "            words = bow_converter.get_feature_names()\n",
    "            #print('words = ',words)\n",
    "            bow_arr.append(bow)\n",
    "        if lemma_tag:\n",
    "            #tags = bow_converter.get_feature_names()\n",
    "            tags_arr.append(tags)\n",
    "\n",
    "print(bow_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5001x299 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 21861 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything up-to-date\r\n"
     ]
    }
   ],
   "source": [
    "!git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
